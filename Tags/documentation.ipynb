{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8133d2fc-61a5-42c4-9e0d-50409170f2a0",
   "metadata": {},
   "source": [
    "# clustering notes and documents based on tags \n",
    "for a while i have been using markdown to take notes and tags are good way to sort and find related documents.\n",
    "clustering notes based on tags could be usefull way to  find and review related pieces of information in your library of notes.\n",
    "\n",
    "## vectorisation and embeding\n",
    "to efectively cluster documentts based on tags we could go with few aproach. \n",
    "- create giant booolean vector where 1 means that document has that tag, and 0 means it doesnt.\n",
    "\n",
    "this aproach can work but it doesnt take into acount that some tags are related. for example document with the tags:[#math] and [#python] would be as far apart(norm/distance) as [#cpp] and [#foodrecipes]. math and python are clearly more related to each other but this model wouldnt take it into account.\n",
    "\n",
    "- create semantic embedings of the tags based on what topics they represent and vector of the documment woudl be mean of the tags it has\n",
    "this aproach needs little more work, but solves the problem of related tags. for the sake of demonstration im using handwriten weights/vector embedings of few predeterminet tags though there are algoriths/ libraries that woudl make embeding out of any tag.\n",
    "[math, coding, art, fantasy, gaming, hobby] this will be semantinc axis that I woudl use for each tag\n",
    "exmple\n",
    "    \"NLA\":   [0.90, 0.20, 0.00, 0.00, 0.00, 0.00] since its mainly about math but also we learn numerical methods for cooding\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a775b5-1b03-4080-9393-56c52966b14d",
   "metadata": {},
   "source": [
    "## Code and explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7f60bf-0c2c-4c0a-a7b5-f74b53db9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727df382-f719-4af5-b63c-6f8862aa0961",
   "metadata": {},
   "source": [
    "### norms \n",
    "few norms for testing\n",
    "infinity norm is interesting as it will since its searching for maximum axis that woudl mean it would only take main topic of the document and igonore any other subtopic on semantic axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac594bf-8360-46ee-a2db-cc982bdcc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm2 (a): return np.sqrt((a ** 2).sum(axis = -1))\n",
    "def norm1 (a): return np.abs(a).sum(axis=-1)\n",
    "def normifn (a): return np.max(np.abs(a), axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2838b-da37-431c-a64e-3aeb82852c19",
   "metadata": {},
   "source": [
    "### Density-based clustering (DBSCAN)\n",
    "Switching from agglomerative merging to DBSCAN so we don't need to pre-pick the number of clusters.\n",
    "- eps controls how close tag-embedding vectors must be to be neighbors.\n",
    "- min_samples sets how many neighbors (including the point itself) are needed to form a dense core.\n",
    "- Points that never reach that density become noise with label -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49396c7c-6bde-46df-8bb3-d45aa6932259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(points, norm):\n",
    "    n = len(points)\n",
    "    d = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist = norm(points[i] - points[j])\n",
    "            d[i, j] = d[j, i] = dist\n",
    "    return d\n",
    "\n",
    "def dbscan(dist_matrix, eps, min_samples):\n",
    "    n = dist_matrix.shape[0]\n",
    "    labels = -np.ones(n, dtype=int)\n",
    "    visited = np.zeros(n, dtype=bool)\n",
    "    cluster_id = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "        visited[i] = True\n",
    "        neighbors = np.where(dist_matrix[i] <= eps)[0]\n",
    "        if neighbors.size < min_samples:\n",
    "            labels[i] = -1\n",
    "            continue\n",
    "\n",
    "        labels[i] = cluster_id\n",
    "        seeds = [p for p in neighbors if p != i]\n",
    "\n",
    "        while seeds:\n",
    "            point = seeds.pop()\n",
    "            if not visited[point]:\n",
    "                visited[point] = True\n",
    "                point_neighbors = np.where(dist_matrix[point] <= eps)[0]\n",
    "                if point_neighbors.size >= min_samples:\n",
    "                    for nb in point_neighbors:\n",
    "                        if nb not in seeds:\n",
    "                            seeds.append(nb)\n",
    "            if labels[point] == -1:\n",
    "                labels[point] = cluster_id\n",
    "            elif labels[point] != cluster_id:\n",
    "                labels[point] = cluster_id\n",
    "        cluster_id += 1\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df7587b-7550-4e7e-b51b-2018d1598e1c",
   "metadata": {},
   "source": [
    "### Distance matrix helper\n",
    "We pre-compute pairwise distances between document embeddings once and reuse them in DBSCAN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c8502a-a4a5-404f-b935-0663ebb4ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_clusters(labels, names):\n",
    "    groups = {}\n",
    "    for idx, label in enumerate(labels):\n",
    "        groups.setdefault(label, []).append(names[idx])\n",
    "    return groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181db59c-1d72-4b8f-8541-626d23bf7383",
   "metadata": {},
   "source": [
    "### sample data and sample tag vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a4ce6c-5658-435e-976d-4ccc5a1e5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic axes:\n",
    "#[math, coding, art, fantasy, gaming, hobby]\n",
    "tag_vectors = {\n",
    "    \"math\":            np.array([1.00, 0.00, 0.00, 0.00, 0.00, 0.00]),\n",
    "    \"NLA\":             np.array([0.90, 0.20, 0.00, 0.00, 0.00, 0.00]),\n",
    "    \"calculus\":        np.array([0.85, 0.00, 0.00, 0.00, 0.00, 0.00]),\n",
    "    \"analysis\":        np.array([0.80, 0.00, 0.00, 0.00, 0.00, 0.00]),\n",
    "\n",
    "    \"coding\":          np.array([0.00, 1.00, 0.00, 0.00, 0.00, 0.00]),\n",
    "    \"python\":          np.array([0.00, 0.90, 0.00, 0.00, 0.00, 0.00]),\n",
    "    \"cpp\":             np.array([0.00, 0.80, 0.00, 0.00, 0.00, 0.00]),\n",
    "    \"algorithms\":      np.array([0.10, 0.85, 0.00, 0.00, 0.00, 0.00]),\n",
    "    \"project\":         np.array([0.00, 0.70, 0.00, 0.00, 0.00, 0.30]),  \n",
    "\n",
    "    \"art\":             np.array([0.00, 0.00, 1.00, 0.00, 0.00, 0.00]),\n",
    "    \"design\":          np.array([0.00, 0.00, 0.85, 0.00, 0.00, 0.00]),\n",
    "    \"drawing\":         np.array([0.00, 0.00, 0.90, 0.00, 0.00, 0.30]),\n",
    "\n",
    "    \"fantasy\":         np.array([0.00, 0.00, 0.00, 1.00, 0.00, 0.00]),\n",
    "    \"worldbuilding\":   np.array([0.00, 0.00, 0.00, 0.90, 0.00, 0.30]),\n",
    "    \"lore\":            np.array([0.00, 0.00, 0.00, 0.85, 0.00, 0.00]),\n",
    "    \"dnd\":             np.array([0.00, 0.00, 0.00, 0.80, 0.30, 0.30]),  \n",
    "\n",
    "    \"gaming\":          np.array([0.00, 0.00, 0.00, 0.00, 1.00, 0.00]),\n",
    "    \"game-dev\":        np.array([0.00, 0.50, 0.00, 0.00, 0.90, 0.00]),\n",
    "    \"helldivers\":      np.array([0.00, 0.00, 0.00, 0.00, 0.95, 0.00]),\n",
    "\n",
    "    \"hobby\":           np.array([0.00, 0.00, 0.00, 0.00, 0.00, 1.00]),\n",
    "    \"journal\":         np.array([0.00, 0.00, 0.00, 0.00, 0.00, 0.90]),\n",
    "    \"recipes\":         np.array([0.00, 0.00, 0.00, 0.00, 0.00, 0.80])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e610d278-3f9f-4ce0-aab5-09336c014af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI generated sample data\n",
    "documents = {\n",
    "    # Pure Math -----\n",
    "    \"la_notes\":              [\"math\", \"linear-algebra\"],\n",
    "    \"calc_homework\":         [\"math\", \"calculus\"],\n",
    "    \"analysis_summary\":      [\"math\", \"analysis\"],\n",
    "    \"probability_notes\":     [\"math\"],\n",
    "\n",
    "    # ----- Pure Coding -----\n",
    "    \"python_basics\":         [\"coding\", \"python\"],\n",
    "    \"cpp_optimizations\":     [\"coding\", \"cpp\"],\n",
    "    \"algo_design\":           [\"coding\", \"algorithms\"],\n",
    "    \"project_todo\":          [\"coding\", \"project\"],\n",
    "\n",
    "    # ----- Pure Art -----\n",
    "    \"portrait_sketch\":       [\"art\", \"drawing\"],\n",
    "    \"ui_design_draft\":       [\"art\", \"design\"],\n",
    "    \"color_theory\":          [\"art\"],\n",
    "\n",
    "    # ----- Pure Fantasy -----\n",
    "    \"dnd_session_1\":         [\"dnd\", \"worldbuilding\"],\n",
    "    \"world_map\":             [\"fantasy\", \"worldbuilding\"],\n",
    "    \"ancient_lore\":          [\"fantasy\", \"lore\"],\n",
    "    \"magic_system\":          [\"fantasy\"],\n",
    "\n",
    "    # ----- Pure Gaming -----\n",
    "    \"game_review_hd2\":       [\"gaming\", \"helldivers\"],\n",
    "    \"build_guide_slayer\":    [\"gaming\"],\n",
    "    \"game_dev_plan\":         [\"gaming\", \"game-dev\", \"project\"],\n",
    "\n",
    "    # ----- Pure Hobby -----\n",
    "    \"daily_journal\":         [\"hobby\", \"journal\"],\n",
    "    \"recipe_tacos\":          [\"hobby\", \"recipes\"],\n",
    "    \"fitness_log\":           [\"hobby\"],\n",
    "\n",
    "    # ----- Math + Coding Mix -----\n",
    "    \"math_for_algos\":        [\"math\", \"algorithms\"],\n",
    "    \"python_numerics\":       [\"coding\", \"math\", \"python\"],\n",
    "    \"machine_learning_intro\":[\"math\", \"coding\", \"algorithms\", \"python\"],\n",
    "    \"project_summary\":       [\"coding\", \"math\", \"project\"],\n",
    "\n",
    "    # ----- Coding + Fantasy Mix -----\n",
    "    \"python_for_dnd\":        [\"coding\", \"dnd\"],\n",
    "    \"campaign_tracker_tool\": [\"coding\", \"fantasy\", \"project\"],\n",
    "    \"map_generator_code\":    [\"coding\", \"worldbuilding\", \"project\"],\n",
    "    \"spell_calc_program\":    [\"coding\", \"fantasy\", \"math\"],\n",
    "\n",
    "    # ----- Art + Fantasy Mix -----\n",
    "    \"character_concepts\":    [\"art\", \"fantasy\"],\n",
    "    \"world_map_art\":         [\"art\", \"worldbuilding\"],\n",
    "    \"magic_creature_design\": [\"art\", \"fantasy\", \"design\"],\n",
    "    \"ui_for_fantasy_game\":   [\"art\", \"gaming\", \"design\"],\n",
    "\n",
    "    # ----- Coding + Gaming Mix -----\n",
    "    \"ai_bot_for_games\":      [\"coding\", \"gaming\", \"algorithms\"],\n",
    "    \"game_modding_notes\":    [\"gaming\", \"coding\"],\n",
    "    \"game_dev_diary\":        [\"gaming\", \"project\", \"journal\"],\n",
    "    \"procedural_generation\": [\"coding\", \"game-dev\", \"fantasy\"],\n",
    "\n",
    "    # ----- Weird Crossovers (stress tests) -----\n",
    "    \"math_of_color\":         [\"math\", \"art\"],\n",
    "    \"fantasy_statistics\":    [\"math\", \"fantasy\"],\n",
    "    \"cooking_for_dnd_party\": [\"hobby\", \"fantasy\", \"recipes\"],\n",
    "    \"art_of_algorithms\":     [\"math\", \"coding\", \"art\"],\n",
    "    \"lore_based_ai\":         [\"coding\", \"fantasy\", \"algorithms\"],\n",
    "    \"game_study_notebook\":   [\"math\", \"gaming\", \"journal\"],\n",
    "    \"dnd_budget_sheet\":      [\"math\", \"hobby\", \"dnd\"],\n",
    "    \"fantasy_cooking\":       [\"fantasy\", \"recipes\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "248ffab2-20b3-4eec-aa4e-c1e1945c6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'build_guide_slayer', 'game_review_hd2'}\n",
      "\n",
      "\n",
      "{'la_notes', 'probability_notes', 'calc_homework', 'analysis_summary'}\n",
      "\n",
      "\n",
      "{'world_map_art', 'character_concepts', 'magic_creature_design'}\n",
      "\n",
      "\n",
      "{'algo_design', 'math_for_algos', 'python_basics', 'game_dev_plan', 'art_of_algorithms', 'cpp_optimizations', 'spell_calc_program', 'ai_bot_for_games', 'procedural_generation', 'fantasy_statistics', 'project_todo', 'project_summary', 'campaign_tracker_tool', 'map_generator_code', 'python_for_dnd', 'game_modding_notes', 'python_numerics', 'math_of_color', 'machine_learning_intro', 'lore_based_ai'}\n",
      "\n",
      "\n",
      "{'game_study_notebook', 'daily_journal', 'recipe_tacos', 'world_map', 'fitness_log', 'dnd_session_1', 'dnd_budget_sheet', 'game_dev_diary', 'magic_system', 'cooking_for_dnd_party', 'fantasy_cooking', 'ancient_lore'}\n",
      "\n",
      "\n",
      "{'ui_design_draft', 'color_theory', 'ui_for_fantasy_game', 'portrait_sketch'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def document_vector(tags):\n",
    "    \"\"\"Average vector of a set of tags.\"\"\"\n",
    "    vecs = [tag_vectors[tag] for tag in tags if tag in tag_vectors]\n",
    "    if not vecs:\n",
    "        return np.zeros(6)\n",
    "    return np.mean(vecs, axis=0)\n",
    "    \n",
    "# converting docs to embeddings\n",
    "doc_embeddings = {name: document_vector(tags) for name, tags in documents.items()}\n",
    "names = list(doc_embeddings.keys())\n",
    "array = np.vstack([vector for vector in doc_embeddings.values()])\n",
    "\n",
    "# Distance matrix + DBSCAN parameters\n",
    "dist_matrix = pairwise_distances(array, norm2)\n",
    "EPS = np.median(dist_matrix[np.triu_indices_from(dist_matrix, k=1)])  # start with median distance\n",
    "MIN_SAMPLES = 3\n",
    "\n",
    "labels = dbscan(dist_matrix, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "clusters = summarize_clusters(labels, names)\n",
    "\n",
    "print(f\"DBSCAN eps={EPS:.3f}, min_samples={MIN_SAMPLES}\")\n",
    "for cid, docs in sorted(clusters.items()):\n",
    "    label = \"Noise\" if cid == -1 else f\"Cluster {cid}\"\n",
    "    print(f\"{label}: {docs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96177ce0-8e05-4a60-a9ca-050950c66abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}